# 📚 Case Studies: Entropy & Diversity in NLG

---

### 🧪 Case Study 1: Hallucination Detection in LLMs

- **Source:** _Nature_ (2024)
- **Finding:** Semantic entropy detected **79–90%** of hallucinations in GPT-4 outputs.
- **Real-world Impact:** In medical diagnosis AI, high entropy flags uncertain or potentially incorrect outputs—helping prevent critical errors (akin to Tesla’s safety innovations).

---

### 🍽️ Case Study 2: E2E NLG Challenge

- **Event:** E2E NLG Challenge (2017)
- **Observation:** AI-generated reviews had **20% lower entropy** than human-written ones, resulting in more repetitive text.
- **Application:** Restaurant chatbots improved diversity by using GANs to promote higher entropy in generated responses.

---

### 📰 Case Study 3: Bias in News Generation

- **Insight:** Low lexical entropy in generated news articles signals bias (i.e., repetitive, one-sided narratives).
- **Research Example:** Comparing CNN vs. Fox, entropy metrics revealed the presence of echo chambers in generated content.

---
