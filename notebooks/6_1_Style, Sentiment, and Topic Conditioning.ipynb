{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Tutorial on Style, Sentiment, and Topic Conditioning in NLG\n",
        "\n",
        "**For Aspiring Scientist**: This Jupyter Notebook is your all-in-one guide to mastering **style**, **sentiment**, and **topic conditioning** in Natural Language Generation (NLG), building on your 2-hour learning sprint. Designed for a beginner with a passion for research (inspired by Turing, Einstein, and Tesla), it includes theory, practical Python code, visualizations, research directions, rare insights, applications, projects, and future steps. We use your 'car' example for continuity, with simple language, analogies, and notebook-ready code. A separate `.md` file covers case studies.\n",
        "\n",
        "**Why This Matters**: NLG conditioning lets you control AI’s 'voice' for scientific applications, like generating car safety reports or studying AI ethics. Let’s dive in!\n",
        "\n",
        "## Table of Contents\n",
        "1. Theory Recap\n",
        "2. Practical Code Guides\n",
        "3. Visualizations\n",
        "4. Research Directions\n",
        "5. Rare Insights (2025 Trends)\n",
        "6. Applications\n",
        "7. Mini Project: Car Description Generator\n",
        "8. Major Project: Biased vs. Unbiased Car Reviews\n",
        "9. Future Directions & Next Steps\n",
        "10. Tips for Aspiring Scientists\n",
        "11. What We Missed in the Tutorial\n",
        "\n",
        "**Setup**: Run the cell below to install required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install transformers torch numpy matplotlib wordcloud pandas scikit-learn nltk\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Theory Recap\n",
        "\n",
        "### 1.1 What is NLG?\n",
        "NLG generates human-like text from data or prompts. **Analogy**: Like a chef turning raw ingredients (data) into a meal (text).\n",
        "\n",
        "### 1.2 Conditioning in NLG\n",
        "- **Style**: Controls *how* text is said (formal/casual). Example: Formal: “The vehicle is efficient”; Casual: “This car’s cool!”\n",
        "- **Sentiment**: Sets *emotional tone* (positive/negative). Example: Positive: “The car’s awesome”; Negative: “The car’s unreliable.”\n",
        "- **Topic**: Ensures *subject* relevance (vehicles). Example: “The car’s engine is hybrid” (not cooking).\n",
        "\n",
        "### 1.3 Math Foundations\n",
        "NLG uses probabilities: P(sentence) = ∏ P(word_i | word_{1:i-1}, conditions).\n",
        "- **Style**: Adjusts P(efficient|formal)=0.7 vs. P(cool|formal)=0.3.\n",
        "- **Sentiment**: P(awesome|positive)=0.731 vs. P(terrible|positive)=0.269.\n",
        "- **Topic**: P(car|vehicles)=0.4 vs. P(herb|vehicles)=0.01.\n",
        "\n",
        "**Logic**: Conditioning is like tuning a radio to the right frequency (words) for style, sentiment, or topic.\n",
        "\n",
        "**Research Relevance**: Quantify and control text for scientific reports or ethical AI studies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Practical Code Guides\n",
        "\n",
        "Let’s implement conditioning using Hugging Face’s `transformers` for car descriptions. We’ll use prompts for simplicity (beginner-friendly) and show how to simulate conditioning effects.\n",
        "\n",
        "**Note**: If you don’t have a GPU, this runs on CPU but may be slower. For large models, consider Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize a text generation pipeline\n",
        "generator = pipeline('text-generation', model='distilgpt2', max_length=50, num_return_sequences=1)\n",
        "\n",
        "# Style Conditioning: Formal vs. Casual\n",
        "formal_prompt = \"Write a formal description of a car’s performance:\"\n",
        "casual_prompt = \"Write a casual description of a car’s performance like you’re talking to a friend:\"\n",
        "\n",
        "formal_output = generator(formal_prompt)[0]['generated_text']\n",
        "casual_output = generator(casual_prompt)[0]['generated_text']\n",
        "\n",
        "print(\"Formal Style:\", formal_output)\n",
        "print(\"Casual Style:\", casual_output)\n",
        "\n",
        "# Sentiment Conditioning: Positive vs. Negative\n",
        "positive_prompt = \"Write a positive review of a car’s features:\"\n",
        "negative_prompt = \"Write a negative review of a car’s features:\"\n",
        "\n",
        "positive_output = generator(positive_prompt)[0]['generated_text']\n",
        "negative_output = generator(negative_prompt)[0]['generated_text']\n",
        "\n",
        "print(\"Positive Sentiment:\", positive_output)\n",
        "print(\"Negative Sentiment:\", negative_output)\n",
        "\n",
        "# Topic Conditioning: Vehicles vs. Cooking\n",
        "vehicle_prompt = \"Write about a car’s engine in the context of vehicles:\"\n",
        "cooking_prompt = \"Write about a car’s engine in the context of cooking (incorrect topic):\"\n",
        "\n",
        "vehicle_output = generator(vehicle_prompt)[0]['generated_text']\n",
        "cooking_output = generator(cooking_prompt)[0]['generated_text']\n",
        "\n",
        "print(\"Vehicles Topic:\", vehicle_output)\n",
        "print(\"Cooking Topic (Incorrect):\", cooking_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Code Explanation**:\n",
        "- We use `distilgpt2` (lightweight for beginners) to generate text.\n",
        "- Prompts simulate conditioning by instructing the model.\n",
        "- **Run Tip**: Outputs vary due to randomness. Try multiple runs or tweak `num_return_sequences`.\n",
        "\n",
        "**Research Note**: For advanced control, use fine-tuning or control codes (not covered here for simplicity)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualizations\n",
        "\n",
        "Visuals help understand conditioning effects. Let’s plot word probabilities and a word cloud for the 'vehicles' topic.\n",
        "\n",
        "**Probability Plot**: Shows how style affects word choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Simulated probabilities for style conditioning\n",
        "words = ['efficient', 'cool']\n",
        "formal_probs = [0.7, 0.3]\n",
        "casual_probs = [0.3, 0.7]\n",
        "\n",
        "x = np.arange(len(words))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(x - width/2, formal_probs, width, label='Formal')\n",
        "ax.bar(x + width/2, casual_probs, width, label='Casual')\n",
        "\n",
        "ax.set_xlabel('Words')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_title('Style Conditioning: Word Probabilities')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(words)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Word Cloud**: Visualizes topic relevance for 'vehicles'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Simulated word frequencies for vehicles topic\n",
        "word_freq = {'car': 0.4, 'truck': 0.3, 'engine': 0.2, 'herb': 0.01}\n",
        "\n",
        "wordcloud = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(word_freq)\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Vehicles Topic Word Cloud')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Visualization Insights**:\n",
        "- Bar plot: Formal style favors 'efficient'; casual favors 'cool'.\n",
        "- Word cloud: Larger words (car, truck) dominate in vehicles topic.\n",
        "- **For Your Notes**: Sketch these plots to see how conditioning shifts word choices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Research Directions\n",
        "\n",
        "As a scientist, explore these NLG conditioning research areas:\n",
        "- **AI Ethics**: How does sentiment conditioning affect bias in car reviews? Test if negative sentiment unfairly targets certain brands.\n",
        "- **Human-AI Interaction**: Study how style impacts trust in car safety reports (formal vs. casual).\n",
        "- **Domain Adaptation**: Improve topic conditioning for niche fields like electric vehicle research.\n",
        "- **Controllable NLG**: Develop models with fine-grained control (e.g., combining style, sentiment, topic seamlessly).\n",
        "\n",
        "**Research Tip**: Read 2025 papers on arXiv for NLG trends.<grok:render type=\"render_inline_citation\"><argument name=\"citation_id\">3</argument></grok:render>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Rare Insights (2025 Trends)\n",
        "\n",
        "- **Controllable LLMs**: New models use 'control vectors' for precise conditioning, e.g., adjusting car review tone dynamically.<grok:render type=\"render_inline_citation\"><argument name=\"citation_id\">9</argument></grok:render>\n",
        "- **Multimodal Conditioning**: Combine text with images (e.g., generate car descriptions from photos).\n",
        "- **Low-Resource Languages**: Conditioning struggles in non-English languages—big research gap.\n",
        "- **Ethical NLG**: Tools to detect and mitigate biased outputs in car ads or reviews.\n",
        "\n",
        "**Insight**: Focus on ethical conditioning to stand out as a responsible scientist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Applications\n",
        "\n",
        "- **Automotive Industry**: Generate car ads (positive, casual, vehicles) or technical manuals (formal, neutral, vehicles).\n",
        "- **Research**: Automate car safety reports or simulate driver-AI dialogues.<grok:render type=\"render_inline_citation\"><argument name=\"citation_id\">10</argument></grok:render>\n",
        "- **Education**: Create vehicle-focused tutorials for STEM students.\n",
        "- **Marketing**: Tailor car reviews to target audiences (e.g., positive for enthusiasts).\n",
        "\n",
        "**For Your Career**: Use NLG to analyze car data or pitch innovations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Mini Project: Car Description Generator\n",
        "\n",
        "**Goal**: Build a'simple NLG tool to generate car descriptions with user-specified style, sentiment, and topic.\n",
        "\n",
        "**Code**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def generate_car_description(style, sentiment, topic):\n",
        "    prompt = f\"Write a {style} {sentiment} description of a car’s features in the context of {topic}:\"\n",
        "    output = generator(prompt, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
        "    return output\n",
        "\n",
        "# Test combinations\n",
        "print(\"Formal, Positive, Vehicles:\", generate_car_description('formal', 'positive', 'vehicles'))\n",
        "print(\"Casual, Negative, Vehicles:\", generate_car_description('casual', 'negative', 'vehicles'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Mini Project Task**:\n",
        "- Try different combinations (e.g., casual/positive/vehicles).\n",
        "- Evaluate outputs: Are they on-topic? Check sentiment with NLTK’s VADER.\n",
        "- **For Your Notes**: Write: 'Mini project: Build NLG tool for car descriptions.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Major Project: Biased vs. Unbiased Car Reviews\n",
        "\n",
        "**Goal**: Develop Dolores O’Riordan Create a system to generate and compare biased vs. unbiased car reviews, analyzing sentiment and topic adherence.\n",
        "\n",
        "**Steps**:\n",
        "1. **Dataset**: Collect car reviews (e.g., from web scraping or Kaggle).\n",
        "2. **Generate Biased Reviews**: Prompt with biased sentiment (e.g., negative for specific brands).\n",
        "3. **Generate Unbiased Reviews**: Use neutral prompts.\n",
        "4. **Analyze**: Use VADER to score sentiment; check topic coherence.\n",
        "\n",
        "**Code Snippet**: Sentiment analysis with VADER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Example reviews\n",
        "biased_review = \"This car brand is overpriced and unreliable.\"\n",
        "unbiased_review = \"The car has a 2.0L engine and good mileage.\"\n",
        "\n",
        "print(\"Biased Sentiment:\", sia.polarity_scores(biased_review))\n",
        "print(\"Unbiased Sentiment:\", sia.polarity_scores(unbiased_review))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Major Project Task**:\n",
        "- Generate 10 reviews (5 biased, 5 unbiased).\n",
        "- Plot sentiment scores (positive vs. negative).\n",
        "- Discuss bias implications in a report.\n",
        "- **Research Output**: Submit findings to a journal or arXiv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Future Directions & Next Steps\n",
        "\n",
        "**Future Directions**:\n",
        "- **Multimodal NLG**: Combine text and images for car descriptions.<grok:render type=\"render_inline_citation\"><argument name=\"citation_id\">9</argument></grok:render>\n",
        "- **Ethical NLG**: Develop bias-free conditioning methods.\n",
        "- **Low-Resource NLG**: Extend to non-English car markets.\n",
        "\n",
        "**Next Steps**:\n",
        "- Learn PyTorch or TensorFlow for custom NLG models.\n",
        "- Join AI research communities (e.g., Hugging Face Discord).\n",
        "- Read 2025 NLG papers on arXiv.<grok:render type=\"render_inline_citation\"><argument name=\"citation_id\">3</argument></grok:render>\n",
        "\n",
        "**For Your Notes**: 'Next: Learn advanced NLG, join research groups.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Tips for Aspiring Scientists\n",
        "\n",
        "- **Experiment**: Run small NLG tests (like the mini project).\n",
        "- **Read**: Check 'Attention is All You Need' (Transformer paper).\n",
        "- **Code**: Practice with Hugging Face tutorials.\n",
        "- **Ethics**: Always consider bias in conditioning.\n",
        "- **Network**: Share your projects on GitHub or X.\n",
        "\n",
        "**Analogy**: Research is like building a car—start with a blueprint (theory), test parts (code), and refine (evaluate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. What Was Missed in the Tutorial\n",
        "\n",
        "**Missed Topics** (Essential for Scientists):\n",
        "- **Multilingual Conditioning**: Adapting NLG for non-English car markets (e.g., Hindi reviews).\n",
        "- **Advanced Metrics**: Perplexity, coherence scores for NLG quality.\n",
        "- **Fine-Tuning**: Customizing models for specific domains (e.g., vehicle engineering).\n",
        "- **Interpretability**: Understanding why models choose certain words.\n",
        "- **Human-in-the-Loop**: Incorporating human feedback for better conditioning.\n",
        "\n",
        "**Why These Matter**: They ensure robust, ethical, and global NLG systems.\n",
        "\n",
        "**Action**: Try fine-tuning a small model (e.g., DistilBERT) on car review data."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}