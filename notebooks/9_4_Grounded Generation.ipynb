{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounded Generation in Natural Language Generation (NLG): A World-Class Tutorial for Aspiring Scientists\n",
    "\n",
    "Welcome, future scientist! This Jupyter Notebook is your complete guide to mastering **Grounded Generation in NLG**. Designed for beginners but with depth for researchers, it covers everything from basics to cutting-edge ideas. Think of it as your lab notebook, blending theory, code, visualizations, and projects to fuel your scientific journey. We'll use simple language, analogies (like building a Tesla coil), and step-by-step explanations to make complex ideas clear.\n",
    "\n",
    "## Why This Matters\n",
    "As an aspiring scientist, you need tools that are reliable, like a microscope showing true details. Grounded NLG ensures AI-generated text sticks to facts, avoiding errors that could derail research in fields like medicine or climate science. This notebook will equip you with knowledge, skills, and ideas to innovate like Turing, Einstein, or Tesla.\n",
    "\n",
    "## Structure of the Notebook\n",
    "1. **Theory & Tutorials**: From basics to advanced concepts.\n",
    "2. **Practical Code Guides**: Working Python code with explanations.\n",
    "3. **Visualizations**: Plots and diagrams to see the ideas.\n",
    "4. **Applications**: Real-world uses in science and industry.\n",
    "5. **Research Directions & Rare Insights**: Where to go next as a researcher.\n",
    "6. **Mini & Major Projects**: Hands-on tasks with datasets.\n",
    "7. **Exercises**: Practice problems with solutions.\n",
    "8. **Future Directions & Next Steps**: Paths for deeper study.\n",
    "9. **What's Missing in Standard Tutorials**: Gaps filled for scientists.\n",
    "10. **Case Studies**: See separate `Case_Studies.md` for detailed examples.\n",
    "\n",
    "## How to Use This\n",
    "- Run each code cell in Jupyter (Python 3 kernel, install `numpy`, `matplotlib`, `seaborn`, `transformers`).\n",
    "- Take notes: Each section has key points for your research journal.\n",
    "- Sketch visualizations: Descriptions guide your drawings.\n",
    "- Reflect: Pause to think about 'Why?' and 'What if?' like a scientist.\n",
    "- Check `Case_Studies.md` for in-depth examples.\n",
    "\n",
    "Let's begin your journey to becoming a world-class researcher!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory & Tutorials: Understanding Grounded Generation\n",
    "\n",
    "### 1.1 What is NLG?\n",
    "Natural Language Generation (NLG) is when computers write text that sounds human. It turns data (like numbers or images) into sentences. For example:\n",
    "- Input: `{'temp': 25, 'condition': 'sunny'}`\n",
    "- Output: \"It's a sunny day with a temperature of 25°C.\"\n",
    "\n",
    "**Analogy**: NLG is like a chef turning ingredients (data) into a tasty dish (text).\n",
    "\n",
    "### 1.2 Why Grounding?\n",
    "Regular NLG can make mistakes, like saying wrong facts (called 'hallucinations'). Grounded NLG ties text to real sources, like a book or database, so it's true.\n",
    "- **Ungrounded Example**: AI says \"The moon is made of cheese\" (wrong!).\n",
    "- **Grounded Example**: AI checks a science book and says \"The moon is rocky\" (right).\n",
    "\n",
    "**Analogy**: Grounding is like using a map to avoid getting lost.\n",
    "\n",
    "### 1.3 Key Concepts\n",
    "- **Faithfulness**: Text matches the source exactly.\n",
    "- **Relevance**: Only use facts that answer the question.\n",
    "- **Coherence**: Text flows naturally, not robotic.\n",
    "- **Types of Grounding**:\n",
    "  - **Fact-Based**: Use text sources like Wikipedia.\n",
    "  - **Picture-Based**: Describe images.\n",
    "  - **Number-Based**: Summarize data tables.\n",
    "  - **Mixed**: Combine images and text.\n",
    "\n",
    "### 1.4 How It Works\n",
    "Grounded NLG often uses **Retrieval-Augmented Generation (RAG)**:\n",
    "1. Ask a question (e.g., \"What's the capital of France?\").\n",
    "2. Find facts from a source (e.g., \"France's capital is Paris.\").\n",
    "3. Write an answer using those facts (\"The capital is Paris.\").\n",
    "\n",
    "**Math Idea**: Think of it as a probability game. Regular NLG guesses words: P(word | question). Grounded adds facts: P(word | question, facts).\n",
    "\n",
    "### 1.5 Advanced Ideas\n",
    "- **Knowledge Graphs**: Facts stored like a web (e.g., Paris → capital → France).\n",
    "- **Multimodal Grounding**: Mix images, text, and data for richer answers.\n",
    "- **2025 Trends**: AI teams (one finds facts, one writes) and persuasion (ads with truth).\n",
    "\n",
    "**Reflection**: Why is grounding key for science? It ensures trust, like checking lab results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Practical Code Guides: Building Grounded NLG\n",
    "\n",
    "Let's write Python code to see grounded NLG in action. We'll start simple and build up.\n",
    "\n",
    "### 2.1 Simple Template-Based Grounded NLG\n",
    "Use a fact to fill a sentence template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple template-based grounded NLG\n",
    "def template_nlg(fact_dict):\n",
    "    fact = fact_dict.get('fact', 'unknown')\n",
    "    return f\"The fact is: {fact}\"\n",
    "\n",
    "# Example fact\n",
    "fact_dict = {'fact': 'The capital of France is Paris.'}\n",
    "print(template_nlg(fact_dict))  # Output: The fact is: The capital of France is Paris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: This is the simplest grounded NLG. The fact is 'grounded' in the dictionary. No guessing, just filling a blank.\n",
    "\n",
    "### 2.2 Simulated RAG with Cosine Similarity\n",
    "Let's simulate RAG by finding the best fact match and generating text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulate fact database\n",
    "facts = [\n",
    "    {'text': 'France capital is Paris', 'embedding': np.array([0.9, 0.5])},\n",
    "    {'text': 'UK capital is London', 'embedding': np.array([0.2, 0.9])}\n",
    "]\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def rag_nlg(question, facts):\n",
    "    # Simulate question embedding\n",
    "    q_embed = np.array([0.8, 0.6])  # For 'capital France'\n",
    "    # Find best fact\n",
    "    best_score = -1\n",
    "    best_fact = None\n",
    "    for fact in facts:\n",
    "        score = cosine_similarity(q_embed, fact['embedding'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_fact = fact['text']\n",
    "    # Generate answer\n",
    "    return f\"Based on facts: {best_fact}\"\n",
    "\n",
    "# Test\n",
    "print(rag_nlg('What is France capital?', facts))  # Output: Based on facts: France capital is Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: We pretend the question has a number version (embedding). We compare it to fact numbers using cosine similarity (like measuring how close two arrows point). The closest fact is used to answer. In real systems, use libraries like `transformers` for embeddings.\n",
    "\n",
    "### 2.3 Advanced: Using a Pre-Trained Model\n",
    "For real-world grounding, use Hugging Face's `transformers`. This is a simplified version for learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires: pip install transformers torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Simulate a grounded generator (simplified, no external retrieval)\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "\n",
    "def grounded_generate(question, fact):\n",
    "    prompt = f\"Question: {question}\nFact: {fact}\nAnswer based only on the fact:\"\n",
    "    result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Test\n",
    "fact = 'The capital of France is Paris.'\n",
    "print(grounded_generate('What is the capital of France?', fact))  # Output varies but should include 'Paris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: We use a small language model (distilgpt2) and give it a fact to ensure grounding. Real systems would retrieve facts dynamically. Try tweaking the prompt!\n",
    "\n",
    "**Reflection**: How does code make grounding real? It forces the AI to check facts, like a scientist verifying data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations: Seeing Grounded NLG\n",
    "\n",
    "Visuals help you understand, like sketches in Einstein's notebook. Since we can't draw here, we'll code plots and describe diagrams for you to sketch.\n",
    "\n",
    "### 3.1 Plot: Accuracy vs. Grounding Strength\n",
    "Show how grounding improves answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Simulated data\n",
    "facts_used = [0, 1, 2, 3, 4, 5]\n",
    "accuracy = [60, 70, 80, 85, 90, 95]  # % correct\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x=facts_used, y=accuracy, marker='o')\n",
    "plt.title('Accuracy Improves with More Grounding Facts')\n",
    "plt.xlabel('Number of Facts Used')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: More facts (x-axis) mean better answers (y-axis). This shows grounding's power.\n",
    "\n",
    "### 3.2 Diagram to Sketch: RAG Flow\n",
    "- **Draw This**: A flowchart.\n",
    "  - Box 1: 'Question' → Arrow to Box 2: 'Find Facts' (show a library icon).\n",
    "  - Box 2 → Box 3: 'Combine Question + Facts' → Box 4: 'Write Answer'.\n",
    "  - Side Path: Dashed arrow from Question to 'Wrong Answer' (no facts).\n",
    "\n",
    "**Analogy**: Like a librarian finding a book (facts) before summarizing it (answer).\n",
    "\n",
    "**Reflection**: Draw this. How does seeing the flow help you plan experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Applications: Grounded NLG in the Real World\n",
    "\n",
    "Grounded NLG powers science and industry. Here are key uses:\n",
    "- **Healthcare**: Summarize patient data (e.g., \"Blood pressure 120/80, normal\" from records).\n",
    "- **Climate Science**: Turn weather data into reports (e.g., \"Hurricane risk rising based on satellite data\").\n",
    "- **Education**: Create study guides from textbooks.\n",
    "- **Business**: Write accurate product descriptions from specs.\n",
    "- **2025 Example**: AI assistants ground answers in live data (e.g., calendar-based reminders).\n",
    "\n",
    "**Analogy**: Like a scientist writing a paper with citations – grounding makes it trustworthy.\n",
    "\n",
    "**Reflection**: Which field excites you? How could grounding improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Research Directions & Rare Insights\n",
    "\n",
    "As a scientist, think ahead like Turing imagining computers.\n",
    "\n",
    "### 5.1 Cutting-Edge Ideas (2025)\n",
    "- **Agentic Systems**: AI teams (finder, checker, writer) for complex tasks.\n",
    "- **Multimodal Grounding**: Mix text, images, and audio for richer answers.\n",
    "- **Persuasive Grounding**: Combine facts with appealing language (e.g., science outreach).\n",
    "- **Quantum Grounding**: Use probabilistic databases for uncertainty (future tech).\n",
    "\n",
    "### 5.2 Rare Insights\n",
    "- Grounding reduces errors by 20-50% (TruthfulQA benchmark, 2025).\n",
    "- Bias in facts is a hidden trap – always check your sources.\n",
    "- Human-like grounding (from brain studies) could make AI reason better.\n",
    "\n",
    "**Reflection**: What new idea could you test? Maybe grounding for climate models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mini & Major Projects\n",
    "\n",
    "Try these to build skills like a researcher.\n",
    "\n",
    "### 6.1 Mini Project: Weather Report Generator\n",
    "Create a grounded NLG system for weather.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini Project: Weather Report\n",
    "weather_data = [\n",
    "    {'city': 'Paris', 'temp': 25, 'condition': 'sunny'},\n",
    "    {'city': 'London', 'temp': 18, 'condition': 'cloudy'}\n",
    "]\n",
    "\n",
    "def weather_nlg(city):\n",
    "    for data in weather_data:\n",
    "        if data['city'].lower() == city.lower():\n",
    "            return f\"In {data['city']}, it's {data['condition']} with a temperature of {data['temp']}°C.\"\n",
    "    return \"City not found.\"\n",
    "\n",
    "print(weather_nlg('Paris'))  # Output: In Paris, it's sunny with a temperature of 25°C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Add more cities and conditions. Try a new format (e.g., short tweet).\n",
    "\n",
    "### 6.2 Major Project: Grounded Q&A System\n",
    "Build a Q&A system using a fact database. Use a small dataset for learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Major Project: Simple Q&A with Grounding\n",
    "fact_db = [\n",
    "    {'question': 'What is the capital of France?', 'answer': 'Paris', 'embedding': np.array([0.8, 0.6])},\n",
    "    {'question': 'What is the capital of UK?', 'answer': 'London', 'embedding': np.array([0.2, 0.9])}\n",
    "]\n",
    "\n",
    "def qa_nlg(query):\n",
    "    q_embed = np.array([0.8, 0.6])  # Simulate query embedding\n",
    "    best_score = -1\n",
    "    best_answer = 'Sorry, I don’t know.'\n",
    "    for fact in fact_db:\n",
    "        score = cosine_similarity(q_embed, fact['embedding'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_answer = fact['answer']\n",
    "    return f\"Answer: {best_answer}\"\n",
    "\n",
    "print(qa_nlg('Capital of France?'))  # Output: Answer: Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Expand fact_db with 10 facts. Test with new questions. Research idea: Add a truth-checker function.\n",
    "\n",
    "**Reflection**: How could you scale this for real science data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercises: Practice to Learn\n",
    "\n",
    "Build skills with these tasks. Solutions follow.\n",
    "\n",
    "### 7.1 Exercise 1: Template NLG\n",
    "Write a function to generate a grounded sentence from a fact dictionary.\n",
    "\n",
    "**Solution**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_template(fact_dict):\n",
    "    return f\"Did you know? {fact_dict.get('fact', 'No fact provided')}\"\n",
    "\n",
    "print(exercise_template({'fact': 'The sun is a star.'}))  # Output: Did you know? The sun is a star."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Exercise 2: Cosine Similarity\n",
    "Calculate cosine similarity for two vectors by hand and code.\n",
    "\n",
    "**Solution**:\n",
    "- Vectors: A=[0.8, 0.6], B=[0.9, 0.5]\n",
    "- Dot: 0.8*0.9 + 0.6*0.5 = 0.72 + 0.3 = 1.02\n",
    "- Norms: sqrt(0.64 + 0.36) = 1, sqrt(0.81 + 0.25) = 1.02\n",
    "- Similarity: 1.02 / (1 * 1.02) ≈ 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0.8, 0.6])\n",
    "b = np.array([0.9, 0.5])\n",
    "print(cosine_similarity(a, b))  # Output: ~1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reflection**: Try new vectors. How does similarity affect grounding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Future Directions & Next Steps\n",
    "\n",
    "Keep growing as a scientist!\n",
    "\n",
    "- **Learn More**: Study transformers (Hugging Face tutorials), retrieval systems (FAISS), and multimodal AI (CLIP).\n",
    "- **Experiment**: Build a grounded chatbot with a free dataset (e.g., Wikipedia dump).\n",
    "- **Research**: Publish on grounding for your field (e.g., biology or physics).\n",
    "- **Tools**: Try free platforms like Colab or Hugging Face.\n",
    "\n",
    "**Reflection**: What’s one question you want to answer with grounded NLG?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What's Missing in Standard Tutorials\n",
    "\n",
    "Most tutorials skip:\n",
    "- **Scientific Mindset**: Asking 'Why?' and 'What if?' for research.\n",
    "- **Math Details**: Full derivations (like our cosine example).\n",
    "- **Ethics**: Bias in facts can harm – always audit sources.\n",
    "- **Real-World Link**: Connecting to fields like climate or health.\n",
    "- **Beginner Clarity**: Breaking down jargon (e.g., 'embedding' = number version of words).\n",
    "\n",
    "This notebook fills these gaps, giving you a scientist’s toolkit.\n",
    "\n",
    "**Reflection**: How does this prepare you better than a basic guide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Case Studies\n",
    "See `Case_Studies.md` for detailed examples, including:\n",
    "- Medical report grounding.\n",
    "- Climate data summaries.\n",
    "- Persuasive AI for science outreach.\n",
    "\n",
    "**Next Steps**: Run this notebook, sketch diagrams, try projects, and read case studies. You're on your way to becoming a groundbreaking researcher!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}