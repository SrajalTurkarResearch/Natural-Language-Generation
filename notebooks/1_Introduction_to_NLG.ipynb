{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Generation (NLG) Tutorial\n",
    "\n",
    "Welcome to this comprehensive Jupyter Notebook on **Natural Language Generation (NLG)**! As an aspiring scientist, you're diving into a fascinating AI subfield that generates human-like text from data. This notebook is your one-stop resource, assuming no prior knowledge and covering:\n",
    "- **Theory**: Core concepts, mathematical foundations, and NLG vs. NLP.\n",
    "- **Practical Code Guides**: Hands-on examples with Python.\n",
    "- **Visualizations**: Diagrams and plots to clarify concepts.\n",
    "- **Applications**: Real-world use cases with case studies.\n",
    "- **Research Directions**: Cutting-edge areas for scientific exploration.\n",
    "- **Rare Insights**: Lesser-known challenges and opportunities in NLG.\n",
    "- **Mini and Major Projects**: Practical projects to build your skills.\n",
    "- **Additional Topics**: Evaluation metrics, advanced techniques, and ethical considerations not covered in the previous tutorial.\n",
    "\n",
    "This notebook is designed to be beginner-friendly, using simple language, analogies, and a logical structure to help you take notes and understand the logic behind NLG. By the end, you'll have a solid foundation to pursue NLG research and take a significant step in your scientific career.\n",
    "\n",
    "## Table of Contents\n",
    "1. **What is NLG?**\n",
    "   - Definition and Analogy\n",
    "   - Why NLG Matters for Scientists\n",
    "2. **NLG vs. NLP**\n",
    "   - Key Differences and Complementary Roles\n",
    "3. **Key Components of NLG**\n",
    "   - Data Input, Content Planning, Sentence Planning, Evaluation\n",
    "4. **Mathematical Foundations**\n",
    "   - Probability and N-gram Models\n",
    "   - Neural Networks and Transformers\n",
    "   - Code: Bigram Probability Calculation\n",
    "5. **Types of NLG Systems**\n",
    "   - Rule-Based, Statistical, Neural\n",
    "6. **Applications of NLG**\n",
    "   - Case Studies: Weather Reports, Chatbots, Medical Reports\n",
    "7. **Practical Tutorial: Building an NLG System**\n",
    "   - Code: Rule-Based Weather Report Generator\n",
    "   - Visualization: NLG Pipeline\n",
    "8. **Advanced NLG Techniques**\n",
    "   - Fine-Tuning Transformers\n",
    "   - Code: Using Hugging Face Transformers\n",
    "9. **Evaluation Metrics**\n",
    "   - BLEU, ROUGE, Human Evaluation\n",
    "   - Code: Calculating BLEU Score\n",
    "10. **Challenges and Rare Insights**\n",
    "    - Bias, Scalability, Contextual Understanding\n",
    "11. **Research Directions**\n",
    "    - Emerging Areas for Scientists\n",
    "12. **Mini and Major Projects**\n",
    "    - Mini Project: Enhanced Weather Report\n",
    "    - Major Project: Multilingual News Summarizer\n",
    "13. **Getting Started as a Researcher**\n",
    "    - Tools, Resources, and Tips\n",
    "14. **Conclusion and Next Steps**\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Natural Language Generation?\n",
    "\n",
    "### Definition and Analogy\n",
    "**Natural Language Generation (NLG)** is an AI subfield that generates coherent, meaningful, and contextually appropriate text from non-linguistic data (e.g., numbers, tables).\n",
    "\n",
    "**Example**: From `{temperature: 25, condition: sunny}`, NLG produces: “It’s a sunny day with a temperature of 25°C.”\n",
    "\n",
    "**Analogy**: NLG is like a storyteller who takes raw facts (e.g., a list of events) and weaves them into a narrative. Imagine a chef turning raw ingredients (data) into a delicious dish (text).\n",
    "\n",
    "### Why NLG Matters for Scientists\n",
    "- **Communication**: Turns complex data into readable summaries.\n",
    "- **Automation**: Saves time on repetitive tasks like report writing.\n",
    "- **Research**: Explores AI’s ability to mimic human creativity.\n",
    "\n",
    "NLG is used in chatbots, automated journalism, and scientific reporting, making it a key area for advancing AI research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLG vs. NLP\n",
    "\n",
    "### Key Differences\n",
    "- **NLP (Natural Language Processing)**:\n",
    "  - **Focus**: Understands and interprets human language.\n",
    "  - **Tasks**: Sentiment analysis, translation, text classification.\n",
    "  - **Example**: Determining if a review is positive or negative.\n",
    "  - **Analogy**: A detective decoding clues from text.\n",
    "- **NLG (Natural Language Generation)**:\n",
    "  - **Focus**: Generates human-like text from data.\n",
    "  - **Tasks**: Creating reports, stories, dialogue.\n",
    "  - **Example**: Writing a weather forecast from data.\n",
    "  - **Analogy**: A writer crafting a story from raw ideas.\n",
    "\n",
    "### Complementary Roles\n",
    "NLP and NLG often work together. For example, in a chatbot:\n",
    "- NLP interprets: “What’s the weather?”\n",
    "- NLG responds: “It’s sunny with a temperature of 25°C.”\n",
    "\n",
    "**Visualization**:\n",
    "```plaintext\n",
    "[User Input: Text] → [NLP: Understands] → [NLG: Generates] → [Output: Text]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Key Components of NLG\n",
    "\n",
    "NLG systems follow a pipeline:\n",
    "1. **Data Input and Preprocessing**: Clean and organize raw data (e.g., `{temp: 25.6}` → `25°C`).\n",
    "2. **Content Planning**: Decide *what* to say (e.g., select temperature and condition).\n",
    "3. **Sentence Planning and Realization**: Decide *how* to say it (e.g., “It’s sunny” vs. “The weather is sunny”).\n",
    "4. **Evaluation**: Assess fluency, accuracy, and relevance.\n",
    "\n",
    "**Example**: From `{temp: 25, condition: sunny}`, generate “It’s a sunny day with a temperature of 25°C.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mathematical Foundations\n",
    "\n",
    "### Probability and Language Models\n",
    "NLG uses language models to predict likely words. **N-gram models** calculate the probability of a word based on previous words.\n",
    "\n",
    "**Bigram Formula**:\n",
    "\\[ P(w_n | w_{n-1}) = \\frac{\\text{Count}(w_{n-1}, w_n)}{\\text{Count}(w_{n-1})} \\]\n",
    "\n",
    "### Code: Bigram Probability Calculation\n",
    "Let’s calculate bigram probabilities from a small corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(is | cat) = 1.0\n",
      "P(sleeping | is) = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate bigram probabilities\n",
    "from collections import Counter\n",
    "\n",
    "# Corpus\n",
    "corpus = [\"The cat is sleeping\", \"The cat is eating\"]\n",
    "words = [sentence.split() for sentence in corpus]\n",
    "\n",
    "# Count bigrams and single words\n",
    "bigrams = []\n",
    "singles = []\n",
    "for sentence in words:\n",
    "    for i in range(len(sentence)-1):\n",
    "        bigrams.append((sentence[i], sentence[i+1]))\n",
    "        singles.append(sentence[i])\n",
    "\n",
    "bigram_counts = Counter(bigrams)\n",
    "single_counts = Counter(singles)\n",
    "\n",
    "# Calculate P(is | cat)\n",
    "p_is_given_cat = bigram_counts[('cat', 'is')] / single_counts['cat']\n",
    "print(f\"P(is | cat) = {p_is_given_cat}\")  # Expected: 1.0\n",
    "\n",
    "# Calculate P(sleeping | is)\n",
    "p_sleeping_given_is = bigram_counts[('is', 'sleeping')] / single_counts['is']\n",
    "print(f\"P(sleeping | is) = {p_sleeping_given_is}\")  # Expected: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "```\n",
    "P(is | cat) = 1.0\n",
    "P(sleeping | is) = 0.5\n",
    "```\n",
    "\n",
    "### Neural Networks and Transformers\n",
    "Modern NLG uses **Transformers**, which consist of:\n",
    "- **Encoder**: Understands input data.\n",
    "- **Decoder**: Generates text.\n",
    "- **Attention**: Focuses on relevant input parts.\n",
    "\n",
    "**Visualization**:\n",
    "```plaintext\n",
    "[Input Data] → [Encoder: Vector Representation] → [Attention: Focus on Key Parts] → [Decoder: Generate Text]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Types of NLG Systems\n",
    "\n",
    "1. **Rule-Based**: Uses templates (e.g., “The temperature is [TEMP]°C”).\n",
    "   - **Pros**: Simple, accurate.\n",
    "   - **Cons**: Rigid, not creative.\n",
    "2. **Statistical**: Uses n-grams or Markov models.\n",
    "   - **Pros**: More flexible.\n",
    "   - **Cons**: Less coherent.\n",
    "3. **Neural**: Uses Transformers (e.g., GPT).\n",
    "   - **Pros**: Fluent, creative.\n",
    "   - **Cons**: Resource-intensive, bias-prone.\n",
    "\n",
    "**Comparison**:\n",
    "| Type | Flexibility | Complexity | Use Case |\n",
    "|------|-------------|------------|----------|\n",
    "| Rule-Based | Low | Low | Weather reports |\n",
    "| Statistical | Medium | Medium | Early chatbots |\n",
    "| Neural | High | High | Creative writing |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Applications of NLG\n",
    "\n",
    "### Overview\n",
    "NLG is used in:\n",
    "- **Business**: Financial reports, product descriptions.\n",
    "- **Healthcare**: Medical summaries.\n",
    "- **Media**: News articles, sports commentary.\n",
    "- **Education**: Personalized learning materials.\n",
    "- **Customer Service**: Chatbots.\n",
    "- **Science**: Summarizing research data.\n",
    "\n",
    "### Case Studies\n",
    "1. **Weather Reports**:\n",
    "   - Input: `{temp: 25, condition: sunny, humidity: 60}`\n",
    "   - Output: “Today is sunny with a temperature of 25°C and 60% humidity.”\n",
    "   - Impact: Automates forecasting.\n",
    "2. **Chatbots**:\n",
    "   - Input: “What’s my order status?”\n",
    "   - Output: “Your order will ship tomorrow.”\n",
    "   - Impact: Enhances customer service.\n",
    "3. **Medical Reports**:\n",
    "   - Input: `{blood_pressure: 120/80, heart_rate: 70, diagnosis: normal}`\n",
    "   - Output: “The patient’s blood pressure is 120/80, heart rate is 70 bpm, and health is normal.”\n",
    "   - Impact: Saves doctors time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practical Tutorial: Building an NLG System\n",
    "\n",
    "Let’s build a rule-based NLG system to generate weather reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule-Based NLG for Weather Reports\n",
    "weather_data = {\n",
    "    \"temperature\": 25,\n",
    "    \"condition\": \"sunny\",\n",
    "    \"humidity\": 60\n",
    "}\n",
    "\n",
    "def generate_weather_report(data):\n",
    "    temp = data[\"temperature\"]\n",
    "    condition = data[\"condition\"]\n",
    "    humidity = data[\"humidity\"]\n",
    "    \n",
    "    report = []\n",
    "    report.append(f\"The temperature is {temp}°C.\")\n",
    "    report.append(f\"It is {condition} today.\")\n",
    "    report.append(f\"The humidity is {humidity}%.\")\n",
    "    \n",
    "    return \" \".join(report)\n",
    "\n",
    "print(generate_weather_report(weather_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "```\n",
    "The temperature is 25°C. It is sunny today. The humidity is 60%.\n",
    "```\n",
    "\n",
    "**Visualization**: NLG Pipeline\n",
    "Let’s visualize the pipeline using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "stages = ['Raw Data', 'Content Selection', 'Content Structuring', 'Sentence Planning', 'Surface Realization', 'Text Output']\n",
    "for i, stage in enumerate(stages):\n",
    "    ax.text(i*0.2, 0.5, stage, rotation=45, ha='left', va='bottom')\n",
    "    if i < len(stages)-1:\n",
    "        arrow = FancyArrowPatch((i*0.2+0.1, 0.4), ((i+1)*0.2-0.05, 0.4), mutation_scale=15)\n",
    "        ax.add_patch(arrow)\n",
    "ax.set_xlim(0, 1.2)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "plt.title('NLG Pipeline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced NLG Techniques\n",
    "\n",
    "### Fine-Tuning Transformers\n",
    "Neural NLG uses Transformers (e.g., GPT). Fine-tuning adapts a pre-trained model to specific tasks, like generating medical reports.\n",
    "\n",
    "**Code**: Using Hugging Face Transformers for text generation.\n",
    "**Note**: Install `transformers` (`pip install transformers`) and run on a machine with sufficient resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize text generation pipeline\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Generate text\n",
    "prompt = \"The weather today is sunny with a temperature of 25°C.\"\n",
    "output = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Example** (varies due to randomness):\n",
    "```\n",
    "The weather today is sunny with a temperature of 25°C. Expect clear skies and a gentle breeze in the afternoon.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation Metrics\n",
    "\n",
    "Evaluating NLG output is critical. Common metrics include:\n",
    "- **BLEU (Bilingual Evaluation Understudy)**: Measures similarity between generated and reference text.\n",
    "- **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: Focuses on recall of n-grams.\n",
    "- **Human Evaluation**: Assesses fluency and relevance subjectively.\n",
    "\n",
    "**Code**: Calculate BLEU score using `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['It', 'is', 'a', 'sunny', 'day', 'with', 'a', 'temperature', 'of', '25°C']]\n",
    "candidate = ['It', 'is', 'sunny', 'today', 'with', 'a', 'temperature', 'of', '25°C']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(f\"BLEU Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "```\n",
    "BLEU Score: ~0.9 (varies based on implementation)\n",
    "```\n",
    "\n",
    "**Insight**: BLEU is useful but limited; it doesn’t capture fluency or context well. Researching new metrics is a promising area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Challenges and Rare Insights\n",
    "\n",
    "### Challenges\n",
    "- **Coherence**: Ensuring text flows naturally.\n",
    "- **Bias**: Models may produce biased outputs (e.g., gender stereotypes).\n",
    "- **Scalability**: Generating text for large datasets or real-time applications.\n",
    "\n",
    "### Rare Insights\n",
    "- **Hallucination**: Neural NLG models may generate plausible but false information (e.g., “The temperature is 25°C in Antarctica”). Researching hallucination detection is critical.\n",
    "- **Contextual Nuance**: NLG struggles with cultural or domain-specific nuances (e.g., medical terminology). Domain adaptation is a growing field.\n",
    "- **Energy Efficiency**: Training large models like GPT is environmentally costly. Green NLG is an emerging research area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Research Directions\n",
    "\n",
    "As a scientist, explore these areas:\n",
    "- **Bias Mitigation**: Develop methods to reduce bias in generated text.\n",
    "- **Multilingual NLG**: Generate text in multiple languages.\n",
    "- **Explainable NLG**: Make models transparent about their decisions.\n",
    "- **Low-Resource NLG**: Build systems for languages with limited data.\n",
    "- **Green NLG**: Optimize models for energy efficiency.\n",
    "- **Evaluation Metrics**: Create metrics that better capture fluency and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Mini and Major Projects\n",
    "\n",
    "### Mini Project: Enhanced Weather Report\n",
    "**Goal**: Extend the rule-based NLG system to include wind speed and precipitation.\n",
    "**Code**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = {\n",
    "    \"temperature\": 25,\n",
    "    \"condition\": \"sunny\",\n",
    "    \"humidity\": 60,\n",
    "    \"wind_speed\": 10,\n",
    "    \"precipitation\": 0\n",
    "}\n",
    "\n",
    "def enhanced_weather_report(data):\n",
    "    report = []\n",
    "    report.append(f\"The temperature is {data['temperature']}°C.\")\n",
    "    report.append(f\"It is {data['condition']} today.\")\n",
    "    report.append(f\"Humidity is {data['humidity']}%.\")\n",
    "    report.append(f\"Wind speed is {data['wind_speed']} km/h.\")\n",
    "    if data['precipitation'] == 0:\n",
    "        report.append(\"No precipitation is expected.\")\n",
    "    else:\n",
    "        report.append(f\"Expect {data['precipitation']}% chance of rain.\")\n",
    "    return \" \".join(report)\n",
    "\n",
    "print(enhanced_weather_report(weather_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "```\n",
    "The temperature is 25°C. It is sunny today. Humidity is 60%. Wind speed is 10 km/h. No precipitation is expected.\n",
    "```\n",
    "\n",
    "**Research Angle**: Experiment with templates to make reports more engaging or multilingual.\n",
    "\n",
    "### Major Project: Multilingual News Summarizer\n",
    "**Goal**: Build a neural NLG system to summarize news articles in English and Spanish using a Transformer.\n",
    "**Steps**:\n",
    "1. Collect a dataset of news articles (e.g., from Kaggle).\n",
    "2. Use Hugging Face’s `transformers` to fine-tune a model like `facebook/bart-large-cnn`.\n",
    "3. Generate summaries in English and translate to Spanish using a translation model.\n",
    "4. Evaluate using BLEU and human feedback.\n",
    "\n",
    "**Research Angle**: Investigate how well the model handles cultural nuances in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Getting Started as a Researcher\n",
    "\n",
    "### Tools and Libraries\n",
    "- **Python**: Core language.\n",
    "- **NLTK/SpaCy**: For preprocessing.\n",
    "- **Hugging Face Transformers**: For neural NLG.\n",
    "- **PyTorch/TensorFlow**: For custom models.\n",
    "\n",
    "### Resources\n",
    "- **Papers**: Read “Attention is All You Need” (Vaswani et al., 2017).\n",
    "- **Communities**: Join AI groups on X or GitHub.\n",
    "- **Datasets**: Use Kaggle or Hugging Face datasets.\n",
    "\n",
    "### Tips\n",
    "- **Experiment**: Start with small projects like the weather report.\n",
    "- **Publish**: Share findings in journals or on X.\n",
    "- **Ethics**: Prioritize fairness and transparency in NLG systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusion and Next Steps\n",
    "\n",
    "This notebook has provided a comprehensive introduction to NLG, covering theory, code, visualizations, applications, and research directions. As a scientist, NLG offers opportunities to innovate in AI and communication.\n",
    "\n",
    "**Next Steps**:\n",
    "- Run the code examples and tweak them.\n",
    "- Start the mini project to build confidence.\n",
    "- Explore the major project for a deeper challenge.\n",
    "- Read papers and join AI communities to stay updated.\n",
    "\n",
    "**For Your Notes**:\n",
    "- Summarize key terms (e.g., Transformers, BLEU).\n",
    "- Note analogies (e.g., NLG as a storyteller).\n",
    "- List research questions (e.g., “How can we reduce bias in NLG?”).\n",
    "\n",
    "Keep experimenting and stay curious—you’re on your way to becoming an NLG researcher!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
